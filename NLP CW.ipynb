{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05251f8e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "## 1. Domain-specific area\n",
    "\n",
    "\n",
    "Social Media has changed the way businesses interact with their customers forever. In a matter of minutes, thousands of posts could be trending on Twitter. Being able to analyze tweets in real-time, and determine the sentiment that underlies each would be utterly beneficial for a business. \n",
    "\n",
    "Nowadays online reputation is one of the most valuable assets of a brand. A bad review or mistake on social media can be costly if not solved quickly. Twitter sentiment analysis allows a business to keep track of what is being said about the company, a product, or service and can help detect negative sentiment and the reason behind it. Detecting negative trends or angry customers fast is important to deescalate the situation and avoid further negative mentions. \n",
    "\n",
    "But twitter sentiment analysis can not only contribute towards brand monitoring, but it can also gain insight into the preferences of the customers (Pascual 2019). Getting reviews and feedback from customers is extremely valuable for companies. With feedback, companies can change their product or service more to the liking of their customers. Today it is way more convenient for people to tweet about their satisfaction or dissatisfaction about a certain service or product instead of leaving a review on the companies‚Äô website.\n",
    "\n",
    "Therefore, using Twitter sentiment analysis, businesses can scan through thousands of reviews and determine what aspects need to be improved on and what they are doing well. Analyzing tweets can be challenging because tweets are not meant to be well-written reviews with a clear structure and a well summarized thought process but tweets are a rather casual expression of an individual‚Äôs thoughts, limited to 140 characters.\n",
    "\n",
    "Furthermore, tweets often have spelling errors and include emoticons, which makes the task even more challenging (Go et al. 2009). In conclusion, Sentiment analysis helps a business monitor customers‚Äô emotions on social media and makes the business understand how they feel. It adds an extra layer to the traditional metrics used to analyze the performance of brands on social media and provides businesses with powerful opportunities.\n",
    "\n",
    "Businesses could sort data by sentiment manually, but since social media moves so fast and thousands of customers could engage in a matter of minutes this task needs to be automated.   Sentiment analysis needs to be fast, and scalable, so it can provide consistent results with a high level of accuracy (Pascual 2019).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2cb94",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "\n",
    "\n",
    "The dataset used for this coursework was found on Kaggle and is called ‚ÄòTwitter US Airline Sentiment‚Äô (source: https://www.kaggle.com/crowdflower/twitter-airline-sentiment)\n",
    "\n",
    "This data originally came from ‚ÄòCrowdflower's Data for Everyone library‚Äô, which I, unfortunately, cannot access. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\").\n",
    "\n",
    "The data provided on Kaggle is a slightly reformatted version of the source. It includes both a CSV file and an SQLite database. The dataset used in the CW, ‚ÄòTweets.csv‚Äù is available for download as a CSV file and is  3.42 MB big.\n",
    "\n",
    "The CSV contains tweets directed at six different American airlines and the contributors have manually classified the tweets.\n",
    "The columns are:\n",
    "\n",
    "Tweet id: A number to identify the tweet\n",
    "\n",
    "Airline sentiment: either positive, neutral or negative\n",
    "\n",
    "Airline sentiment confidence: A number ranging from 0 to 1, 1 means full confidence in sentiment classification.\n",
    "\n",
    "Negative reason: the reason why sentiment was negative\n",
    "\n",
    "Negative reason confidence: Same confidence score as airline sentiment confidence but about the negative reason\n",
    "\n",
    "Airline: Which airline did the tweet mention/referenced\n",
    "\n",
    "Airline sentiment gold: A lot of missing values, not clear what does columns is supposed to tell\n",
    "\n",
    "Name: Name of the Twitter user without ‚Äú@‚Äù handle\n",
    "\n",
    "The negative reason gold: A lot of missing values, not clear what does columns is supposed to tell\n",
    "\n",
    "Retweet count: The number of times the tweet has been retweeted\n",
    "\n",
    "Text: The actual text of the tweet\n",
    "\n",
    "Tweet cord: A lot of missing values, not clear what does columns is supposed to tell\n",
    "\n",
    "The tweet created: Timestamp of when the tweet was created\n",
    "\n",
    "Tweet Location: A lot of missing values, supposed to tell where the tweet was created\n",
    "\n",
    "User timezone: In what timezone user was when tweeting the tweet\n",
    "\n",
    "In total there are 14640 rows and 14 columns.\n",
    "For this coursework only relevant columns will be used which are: Tweet id (dtype: numpy.int 64), airline sentiment (dtype: string), airline sentiment confidence (dtype: numpy. float64) and text (dtype: string). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa90bf",
   "metadata": {},
   "source": [
    "## 3. Objectives of the project \n",
    "\n",
    "\n",
    "The main objective of this coursework is to successfully build a classifier that can predict the correct sentiment of a given tweet. If a classifier can correctly identify tweets with a 90% accuracy score or above, that would be good enough to potentially contribute to the problem area. \n",
    "\n",
    "But I also want to show that different approaches in text preprocessing lead to different results. \n",
    "Optimizing and choosing the right approach for preprocessing the raw data and the text is of utmost importance to get satisfying results. \n",
    "\n",
    "This coursework can potentially contribute to showing the right/best approach for text and data preprocessing. Two different approaches for text processing will be used and therefore the better approach will have the higher accuracy score.\n",
    "\n",
    "In Section 2.2 of ‚ÄúTwitter Sentiment Classification using Distant Supervision‚Äú from (Go et al. 2009), they discuss the impact of emoticons or emojis when classifying tweets. Emoticons or emojis are nowadays commonly used by Twitter users. In the referenced work they identify emojis as noise and therefore remove them from the training data.\n",
    "\n",
    "In my opinion, emojis can confirm a sentiment like: ‚ÄúI loved your customer service: heart_eyes: (üòç)‚Äù. In this example, the sentiment would have been obvious without the emoji but especially when Twitter users use sarcasm, emojis can be highly valuable to identify the true sentiment of a tweet. For example: ‚ÄúGreat customer service: face_with_rolling_eyes (üôÑ)‚Äù. In this case, the emoji confirms that the tweet was meant to be sarcastic. Removing the emoji would make the rest of the text seem like the tweet was meant to be positive. \n",
    "\n",
    "In this coursework, a python library to decode emojis will be used to identify sentiment even better. So, another objective is to show that emojis are valuable in sentiment analysis and that better results can be achieved when decoding and using emoji language. Unfortunately, most of the tweets do not contain emojis so it will be difficult to gauge whether this approach makes sense/is good.\n",
    "\n",
    "Futhermore for a business it would be almost useless to know if certain tweets have negative or positive sentiment, if the reason as to why is not discovered. That‚Äôs why the last objective of this coursework is to create and train a classifier that can predict the correct reason as to why a tweet was negative. A highly accurate classifier could potentially contribute towards improving twitter sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc8377",
   "metadata": {},
   "source": [
    "## 4. Evaluation methodology \n",
    "\n",
    "\n",
    "For evaluation, the scikit-learn function ‚Äòclassification report‚Äô will be used, which shows precision, recall, f1-score, and the accuracy of a classifier. A confusion matrix will also be shown. \n",
    "\n",
    "As mentioned above, negative reviews or trends online can ruin a brand and drive away potential customers. For businesses, it is more important to reduce and minimize negative press than to improve positive reviews. That‚Äôs why I will pay particular attention to the number of falsely predicted tweets that are classified as negative. If the number of actual negative tweets which were not correctly classified is low, the result is satisfying.The metric I will look at in this case is 'Recall' for the negative label. The recall should be as high as possible for a satisyfing result. \n",
    "\n",
    "Since I also want to show the difference in what impact preprocessing the text has, a total of 3 classifiers will be built and trained for each preprocessing approach:\n",
    "\n",
    "    1.\tThe very baseline Na√Øve Bayes classifier\n",
    "    \n",
    "    2.\tThe more improved Multinominal Na√Øve Bayes classifier\n",
    "    \n",
    "    3.\tThe Random Forest classifier\n",
    "    \n",
    "All 3 of those classifiers will be trained and tested with the basic text process function and evaluation metrics will be gathered. Then all 3 classifiers will be trained and tested using the more optimized process text function to gauge the difference in performance from a text pre-processing angle.\n",
    "\n",
    "At last, the metrics of the classifiers will be compared, and I expect the Random Forest classifier to perform the best out of all 3 because the classifier consists of a large number of individual decision trees that operate as an ensemble. Each tree in the random forest spits out a class prediction and the class with the most votes becomes our model‚Äôs prediction A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models (Yiu 2019).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ff577",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461c91d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 1.3.4\n",
      "emoji: 1.6.1\n",
      "scikit-learn: 0.24.2\n",
      "nltk: 3.6.5\n",
      "re: 2.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mohrj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mohrj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries and printing used version\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report , confusion_matrix , accuracy_score\n",
    "\n",
    "# downloading stopwords and wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "print('Pandas: {}'.format(pd.__version__))\n",
    "print('emoji: {}'.format(emoji.__version__))\n",
    "print('scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('nltk: {}'.format(nltk.__version__))\n",
    "print('re: {}'.format(re.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9960f93d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the csv file into a pandas  dataframe\n",
    "data = pd.read_csv('Airline dataset.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0df546",
   "metadata": {},
   "source": [
    "Now that the data is in a pandas data frame the data will be explored thoroughly below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f58bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica What @dhepburn said.\n",
      "@VirginAmerica plus you've added commercials to the experience... tacky.\n",
      "@VirginAmerica I didn't today... Must mean I need to take another trip!\n",
      "@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
      "@VirginAmerica and it's a really big bad thing about it\n"
     ]
    }
   ],
   "source": [
    "# Exploring how the text data looks like\n",
    "print(data.text[0])\n",
    "print(data.text[1])\n",
    "print(data.text[2])\n",
    "print(data.text[3])\n",
    "print(data.text[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ccbfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000    10445\n",
       "0.6667       71\n",
       "0.6632       35\n",
       "0.6596       30\n",
       "0.6559       30\n",
       "          ...  \n",
       "0.3674        1\n",
       "0.6155        1\n",
       "0.3708        1\n",
       "0.6905        1\n",
       "0.3487        1\n",
       "Name: airline_sentiment_confidence, Length: 1023, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas value counts function to see how many values of each confidence score are present in the dataframe\n",
    "data.airline_sentiment_confidence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ea89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new dataframe with only the relevant columns\n",
    "\n",
    "df = pd.concat([data.tweet_id, data.airline_sentiment,data.airline_sentiment_confidence, data.text], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c2e70b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment  confidence  \\\n",
       "0      570306133677760513   neutral      1.0000   \n",
       "1      570301130888122368  positive      0.3486   \n",
       "2      570301083672813571   neutral      0.6837   \n",
       "3      570301031407624196  negative      1.0000   \n",
       "4      570300817074462722  negative      1.0000   \n",
       "...                   ...       ...         ...   \n",
       "14635  569587686496825344  positive      0.3487   \n",
       "14636  569587371693355008  negative      1.0000   \n",
       "14637  569587242672398336   neutral      1.0000   \n",
       "14638  569587188687634433  negative      1.0000   \n",
       "14639  569587140490866689   neutral      0.6771   \n",
       "\n",
       "                                                    text  \n",
       "0                    @VirginAmerica What @dhepburn said.  \n",
       "1      @VirginAmerica plus you've added commercials t...  \n",
       "2      @VirginAmerica I didn't today... Must mean I n...  \n",
       "3      @VirginAmerica it's really aggressive to blast...  \n",
       "4      @VirginAmerica and it's a really big bad thing...  \n",
       "...                                                  ...  \n",
       "14635  @AmericanAir thank you we got on a different f...  \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...  \n",
       "14637  @AmericanAir Please bring American Airlines to...  \n",
       "14638  @AmericanAir you have my money, you change my ...  \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...  \n",
       "\n",
       "[14640 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New dataframe with improved column names\n",
    "df.columns = ['id', 'sentiment','confidence', 'text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6daabf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 0.3486 @VirginAmerica plus you've added commercials to the experience... tacky.\n",
      "positive 0.3482 @VirginAmerica come back to #PHL already. We need you to take us out of this horrible cold. #pleasecomeback http://t.co/gLXFwP6nQH\n",
      "neutral 0.355 @VirginAmerica Can you find us a flt out of LAX that is sooner than midnight on Monday? That would be great customer service üòÉ\n",
      "positive 0.3579 üòé RT @VirginAmerica: You‚Äôve met your match. Got status on another airline? Upgrade (+restr): http://t.co/RHKaMx9VF5. http://t.co/PYalebgkJt\n",
      "neutral 0.375 @VirginAmerica is saving my sanity right now: http://t.co/ELtBOLjUl9\n",
      "neutral 1.0 @VirginAmerica What @dhepburn said.\n",
      "negative 1.0 @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
      "negative 1.0 @VirginAmerica and it's a really big bad thing about it\n",
      "negative 1.0 @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA\n",
      "positive 1.0 @VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "3    None\n",
       "4    None\n",
       "5    None\n",
       "9    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Interested in difference in confidence, printing 5 rows each for confidence < 0.5 and 5 rows for confidencce = 1\n",
    "\n",
    "df[df['confidence'] < 0.5].head().apply(lambda row:print(row['sentiment'],row['confidence'],row['text']), axis = 1)\n",
    "df[df['confidence'] == 1].head().apply(lambda row:print(row['sentiment'],row['confidence'],row['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cfa18",
   "metadata": {},
   "source": [
    "As seen above some of the tweets with low confidence score are hard to interpret, wich is why I chose to remove all rows in which the confidence score was not 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "026851c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing every row where confidence in sentiment is not at 1, which is the maximum\n",
    "df = df[df.confidence == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf7895b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    7382\n",
       "neutral     1548\n",
       "positive    1515\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing how many rows of each sentiment are left in the df\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c9fb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohrj\\AppData\\Local\\Temp/ipykernel_11716/3670222157.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('confidence', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570295459631263746</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10440</th>\n",
       "      <td>569588464896876545</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir thx for nothing on getting us out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>569587705937600512</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10443</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10444</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10445 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment  \\\n",
       "0      570306133677760513   neutral   \n",
       "1      570301031407624196  negative   \n",
       "2      570300817074462722  negative   \n",
       "3      570300767074181121  negative   \n",
       "4      570295459631263746  positive   \n",
       "...                   ...       ...   \n",
       "10440  569588464896876545  negative   \n",
       "10441  569587705937600512  negative   \n",
       "10442  569587371693355008  negative   \n",
       "10443  569587242672398336   neutral   \n",
       "10444  569587188687634433  negative   \n",
       "\n",
       "                                                    text  \n",
       "0                    @VirginAmerica What @dhepburn said.  \n",
       "1      @VirginAmerica it's really aggressive to blast...  \n",
       "2      @VirginAmerica and it's a really big bad thing...  \n",
       "3      @VirginAmerica seriously would pay $30 a fligh...  \n",
       "4      @VirginAmerica it was amazing, and arrived an ...  \n",
       "...                                                  ...  \n",
       "10440  @AmericanAir thx for nothing on getting us out...  \n",
       "10441  @AmericanAir my flight was Cancelled Flightled...  \n",
       "10442  @AmericanAir leaving over 20 minutes Late Flig...  \n",
       "10443  @AmericanAir Please bring American Airlines to...  \n",
       "10444  @AmericanAir you have my money, you change my ...  \n",
       "\n",
       "[10445 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resetting the index and removing confidence column\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop('confidence', 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59687404",
   "metadata": {},
   "source": [
    "Below, I checked how the emoji library turns emojs into text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013e945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç\n"
     ]
    }
   ],
   "source": [
    "print(df.text[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3ca76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I :red_heart: flying @VirginAmerica. :smiling_face::thumbs_up:\n"
     ]
    }
   ],
   "source": [
    "b = df.text[10]\n",
    "print(emoji.demojize(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30396d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any missing  values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6232bb",
   "metadata": {},
   "source": [
    "As mentioned in the introduction, the best way to preprocess text will be identified. Thats why there are 2 different process_text functions: The basic process_text_basic and the process_text_MB function.\n",
    "\n",
    "In Lecture 5.201: Introduction to sentiment analysis, the lecturer explains the basic approach for sentiment classification using the naive bayes algorithm. The process_text_basic function basically represents this basic approach and prepares the text for the tf-idf vectorizer and serves as a baseline for this coursework.\n",
    "\n",
    "In comparison to this baseline, the process_text_MB function does everything the basic function does like removing punctuation, etc. but also has 3 optimizations:\n",
    "\n",
    "    1.\tTurning emojis into text for better sentiment analysis\n",
    "\n",
    "    2.\tAdd Not_ to every word after a negation until the next punctuation\n",
    "\n",
    "    3.\tOccurrence matters more than frequency -> Tokens occurring more than once will be removed\n",
    "    \n",
    "In both functions the twitter handle, any html links, stopwords and punctuations will be removed so the text is clean and not noisy.\n",
    "\n",
    "Afterwards the whole text will be converted to lowercase aswell as lemmatized and tokenized. \n",
    "The goal of lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base.\n",
    "\n",
    "The decontracted function will be used to decontracte words like \"can't\" into \"can not\" so the above mentioned Step 2 can be properly applied.\n",
    "\n",
    "At first the basic text process function will be used to preprocess the text and the classifiers will be built and evaluted. \n",
    "\n",
    "Then after resetting the changes to the data, the improved text process function will be applied to the dataframe and used to build and train the classifiers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38106237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text so it is usable for td-idf \n",
    "\n",
    "# Source for decontracted function : https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "# Words like \"would've\" would be \"would ve\" after removing puncuation so I think  it is necessary to decontracte the words first\n",
    "# There is also a contractions library for python but I  had several errors trying to install, while the solution below is far from perfect it will be better than nothing!\n",
    "def decontracted(phrase):\n",
    "\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "\n",
    "def  process_text_basic(text):\n",
    "    #removing twitter handle with Regex\n",
    "    text = re.sub(r'@\\S*\\s','',text)\n",
    "    #removing any html links like 'https..'\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url.sub(r'', text)\n",
    "    #removing punctuation\n",
    "    exclude = set(string.punctuation)\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    #converting to lowercase\n",
    "    text =  text.lower()\n",
    "    #removing stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in (stopwords.words('english'))])\n",
    "    #tokenizing the text\n",
    "    text = nltk.word_tokenize(text)\n",
    "    #lemmatizing\n",
    "    wnl = WordNetLemmatizer()\n",
    "    text = [wnl.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4e8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The optimized process_text function\n",
    "\n",
    "\n",
    "def  process_text_MB(text):\n",
    "    \n",
    "    #removing twitter handle with Regex\n",
    "    text = re.sub(r'@\\S*\\s','',text)\n",
    "    \n",
    "    #removing any html links like 'https..'\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url.sub(r'', text)\n",
    "    \n",
    "    #turn emojis into text with emjo library, e.g. I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç ->  I :red_heart: flying @VirginAmerica. :smiling_face::thumbs_up:\n",
    "    text = emoji.demojize(text)\n",
    "    #converting to lowercase\n",
    "    text =  text.lower()\n",
    "\n",
    "    #removing stopwords but leaving 'not', this could be expaneded to never, no, not for negation detection\n",
    "    text = ' '.join([word for word in text.split() if word not in (stopwords)])\n",
    "    \n",
    "    #Simple baseline method: add NOT_ to every word between negation and following punctuation\n",
    "    # source : https://coderedirect.com/questions/368359/how-to-add-tags-to-negated-words-in-strings-that-follow-not-no-and-never\n",
    "    text = re.sub(r'(?:not|never|no)[\\w\\s]+[^\\w\\s]', \n",
    "          lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1not_\\2', match.group(0)), \n",
    "        text,\n",
    "      flags=re.IGNORECASE)\n",
    "    #removing punctuation\n",
    "    exclude = set(string.punctuation)\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    #tokenizing the text\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    #lemmatizing\n",
    "    wnl = WordNetLemmatizer()\n",
    "    text = [wnl.lemmatize(word) for word in text]\n",
    "    #Getting unique tokens, Lecture 5.201, occurence matters more than frequency\n",
    "    text = set(text)\n",
    "    text = list(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112a687",
   "metadata": {},
   "source": [
    "Now that the 2 different text processing functions have been introduced, the basic approach will be applied and the classifiers will be built and tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f12bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the decontracted  function to every row in the text column of the dataframe with a lambda function  \n",
    "df.text = df.text.apply(lambda y: decontracted(y))\n",
    "#Applying the process text function to every row in the text column of the dataframe with a lambda function    \n",
    "df.text = df.text.apply(lambda x: (process_text_basic(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb2cbc0",
   "metadata": {},
   "source": [
    "Below the TF-IDF Countvecotirzer and TFidf transformer from scitkit learn will be used.\n",
    "\n",
    "Every row of the dataframe.text column was processed with the lamba function above and consists of a list of tokens now.\n",
    "\n",
    "So the corpus is every token in the whole text column of the dataframe. This corpus gets transformed into a bag of words and the tfidf will be calculated for every token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "810f5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF-IDF Vectorizer to transform tokens into 1s and 0s\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "corpus = df.text\n",
    "bow = vectorizer.fit_transform(corpus)\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "text_tfidf = transformer.fit_transform(bow)\n",
    "text_tfidf = text_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b2a21c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    7382\n",
      "neutral     1548\n",
      "positive    1515\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Seeing how many rows of each sentiment are left in the df\n",
    "print(df.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69e19d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because of this imbalance training data will be smoothed using the SMOTE function \n",
    "smote = SMOTE()\n",
    "x_sm,y_sm = smote.fit_resample(text_tfidf,df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc5a2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split\n",
    "Y = df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     x_sm, y_sm, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4971ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8203584621699275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.66      0.79      2480\n",
      "     neutral       0.82      0.81      0.82      2398\n",
      "    positive       0.74      0.99      0.84      2431\n",
      "\n",
      "    accuracy                           0.82      7309\n",
      "   macro avg       0.85      0.82      0.82      7309\n",
      "weighted avg       0.85      0.82      0.82      7309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and train Naive Bayes classifier, which will serves as the  baseline for this CW\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "#Predict on test set\n",
    "nb_prediction = nb.predict(X_test)\n",
    "#Get accuary score and classification report for evalutation\n",
    "nb_result = classification_report(y_test, nb_prediction)\n",
    "print(accuracy_score(nb_prediction,y_test))\n",
    "print(nb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fb7f85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8916404432890956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87      2480\n",
      "     neutral       0.91      0.83      0.86      2398\n",
      "    positive       0.93      0.94      0.94      2431\n",
      "\n",
      "    accuracy                           0.89      7309\n",
      "   macro avg       0.89      0.89      0.89      7309\n",
      "weighted avg       0.89      0.89      0.89      7309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and train Multinomial Naive Bayes classifier\n",
    "nb_MB = MultinomialNB()\n",
    "nb_MB.fit(X_train,y_train)\n",
    "#Predict on test set\n",
    "nbMB_prediction =  nb_MB.predict(X_test)\n",
    "#Get accuary score and classification report for evalutation\n",
    "nb_MB_result = classification_report(y_test, nbMB_prediction)\n",
    "print(accuracy_score(nbMB_prediction,y_test))\n",
    "print(nb_MB_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f53c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9217403201532357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90      2480\n",
      "     neutral       0.88      0.96      0.91      2398\n",
      "    positive       0.96      0.94      0.95      2431\n",
      "\n",
      "    accuracy                           0.92      7309\n",
      "   macro avg       0.92      0.92      0.92      7309\n",
      "weighted avg       0.92      0.92      0.92      7309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and train Random Forest classifier\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "random_forest_classifier.fit(X_train,y_train)\n",
    "#Predict on test set\n",
    "random_forest_classifier_prediction =  random_forest_classifier.predict(X_test)\n",
    "#Get accuary score and classification report for evalutation\n",
    "RF_result = classification_report(y_test, random_forest_classifier_prediction)\n",
    "print(accuracy_score(random_forest_classifier_prediction,y_test))\n",
    "print(RF_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70273b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix for random forest classifier\n",
    "cm = confusion_matrix(y_test,random_forest_classifier_prediction)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sentiment_classes = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm, cmap=plt.cm.Blues, annot=True, fmt='d', \n",
    "            xticklabels=sentiment_classes,\n",
    "            yticklabels=sentiment_classes)\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.xlabel('Actual label', fontsize=12)\n",
    "plt.ylabel('Predicted label', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04648cf3",
   "metadata": {},
   "source": [
    "For the basic approach results have been achieved. \n",
    "\n",
    "The Random Forest classifier has already a high accuray score of almost 92% and only labeled 51 actual negative tweets wrongly. It is already a satisfiying result. \n",
    "\n",
    "Below the dataframe will be 'reset' because the process_text_basic function has been applied to the whole dataframe.\n",
    "\n",
    "Then all the steps above will be repeated with the optimized process text function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "007aea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohrj\\AppData\\Local\\Temp/ipykernel_11716/3985424185.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('confidence', 1)\n"
     ]
    }
   ],
   "source": [
    "#Resetting the data\n",
    "data = pd.read_csv('Airline dataset.csv')\n",
    "df = pd.concat([data.tweet_id, data.airline_sentiment,data.airline_sentiment_confidence, data.text], axis = 1)\n",
    "df.columns = ['id', 'sentiment','confidence', 'text']\n",
    "df = df[df.confidence == 1]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop('confidence', 1)\n",
    "\n",
    "#Removing not from stopwords list, because it is needed to add Not_ after every negation\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11989209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the decontracted  function to every row in the text column of the dataframe with a lambda function  \n",
    "df.text = df.text.apply(lambda y: decontracted(y))\n",
    "#Applying the process text function to every row in the text column of the dataframe with a lambda function    \n",
    "df.text = df.text.apply(lambda x: (process_text_MB(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32077e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF-IDF Vectorizer to transform tokens into 1s and 0s\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "corpus = df.text\n",
    "bow = vectorizer.fit_transform(corpus)\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "text_tfidf = transformer.fit_transform(bow)\n",
    "text_tfidf = text_tfidf.toarray()\n",
    "\n",
    "#Because of this imbalance training data will be smoothed using the SMOTE function \n",
    "smote = SMOTE()\n",
    "x_sm,y_sm = smote.fit_resample(text_tfidf,df.sentiment)\n",
    "\n",
    "#Train/test split\n",
    "Y = df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     x_sm, y_sm, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46f7a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8548365029415789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.73      0.84      2480\n",
      "     neutral       0.86      0.84      0.85      2398\n",
      "    positive       0.78      0.99      0.87      2431\n",
      "\n",
      "    accuracy                           0.85      7309\n",
      "   macro avg       0.87      0.86      0.85      7309\n",
      "weighted avg       0.87      0.85      0.85      7309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and train Naive Bayes classifier\n",
    "nb_improved = GaussianNB()\n",
    "nb_improved.fit(X_train, y_train)\n",
    "#Predict on test set\n",
    "nb_prediction_improv = nb_improved.predict(X_test)\n",
    "#Get accuary score and classification report for evalutation\n",
    "nb_improv_result = classification_report(y_test, nb_prediction_improv)\n",
    "print(accuracy_score(nb_prediction_improv,y_test))\n",
    "print(nb_improv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b6f22ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098371870296894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90      2480\n",
      "     neutral       0.91      0.87      0.89      2398\n",
      "    positive       0.92      0.96      0.94      2431\n",
      "\n",
      "    accuracy                           0.91      7309\n",
      "   macro avg       0.91      0.91      0.91      7309\n",
      "weighted avg       0.91      0.91      0.91      7309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and train Multinomial Naive Bayes classifier\n",
    "nb_MB_improv = MultinomialNB()\n",
    "nb_MB_improv.fit(X_train,y_train)\n",
    "#Predict on test set\n",
    "nbMB_prediction_improv =  nb_MB_improv.predict(X_test)\n",
    "#Get accuary score and classification report for evalutation\n",
    "nb_MB_improv_result = classification_report(y_test, nbMB_prediction_improv)\n",
    "print(accuracy_score(nbMB_prediction_improv,y_test))\n",
    "print(nb_MB_improv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fdae898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333698180325626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91      2480\n",
      "     neutral       0.90      0.95      0.92      2398\n",
      "    positive       0.96      0.96      0.96      2431\n",
      "\n",
      "    accuracy                           0.93      7309\n",
      "   macro avg       0.93      0.93      0.93      7309\n",
      "weighted avg       0.93      0.93      0.93      7309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create and train Random Forest classifier\n",
    "random_forest_classifier_improv = RandomForestClassifier()\n",
    "random_forest_classifier_improv.fit(X_train,y_train)\n",
    "#Predict on test set\n",
    "random_forest_classifier_prediction_improv =  random_forest_classifier_improv.predict(X_test)\n",
    "#Get accuary score and classification report for evalutation\n",
    "RF_improv_result = classification_report(y_test, random_forest_classifier_prediction_improv)\n",
    "print(accuracy_score(random_forest_classifier_prediction_improv,y_test))\n",
    "print(RF_improv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cefdf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix for random forest classifier\n",
    "cm = confusion_matrix(y_test,random_forest_classifier_prediction_improv)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sentiment_classes = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm, cmap=plt.cm.Blues, annot=True, fmt='d', \n",
    "            xticklabels=sentiment_classes,\n",
    "            yticklabels=sentiment_classes)\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.xlabel('Actual label', fontsize=12)\n",
    "plt.ylabel('Predicted label', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68559cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.66      0.79      2480\n",
      "     neutral       0.82      0.81      0.82      2398\n",
      "    positive       0.74      0.99      0.84      2431\n",
      "\n",
      "    accuracy                           0.82      7309\n",
      "   macro avg       0.85      0.82      0.82      7309\n",
      "weighted avg       0.85      0.82      0.82      7309\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87      2480\n",
      "     neutral       0.91      0.83      0.86      2398\n",
      "    positive       0.93      0.94      0.94      2431\n",
      "\n",
      "    accuracy                           0.89      7309\n",
      "   macro avg       0.89      0.89      0.89      7309\n",
      "weighted avg       0.89      0.89      0.89      7309\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90      2480\n",
      "     neutral       0.88      0.96      0.91      2398\n",
      "    positive       0.96      0.94      0.95      2431\n",
      "\n",
      "    accuracy                           0.92      7309\n",
      "   macro avg       0.92      0.92      0.92      7309\n",
      "weighted avg       0.92      0.92      0.92      7309\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.73      0.84      2480\n",
      "     neutral       0.86      0.84      0.85      2398\n",
      "    positive       0.78      0.99      0.87      2431\n",
      "\n",
      "    accuracy                           0.85      7309\n",
      "   macro avg       0.87      0.86      0.85      7309\n",
      "weighted avg       0.87      0.85      0.85      7309\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90      2480\n",
      "     neutral       0.91      0.87      0.89      2398\n",
      "    positive       0.92      0.96      0.94      2431\n",
      "\n",
      "    accuracy                           0.91      7309\n",
      "   macro avg       0.91      0.91      0.91      7309\n",
      "weighted avg       0.91      0.91      0.91      7309\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91      2480\n",
      "     neutral       0.90      0.95      0.92      2398\n",
      "    positive       0.96      0.96      0.96      2431\n",
      "\n",
      "    accuracy                           0.93      7309\n",
      "   macro avg       0.93      0.93      0.93      7309\n",
      "weighted avg       0.93      0.93      0.93      7309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Comparing the classification reports for all 6 classifiers\n",
    "print(nb_result, nb_MB_result, RF_result)\n",
    "print(nb_improv_result,nb_MB_improv_result,RF_improv_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c314e1",
   "metadata": {},
   "source": [
    "At last, the dataframe will be reset again to build a classifier which will predict the reason as to why a tweet was negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f748ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohrj\\AppData\\Local\\Temp/ipykernel_11716/2538437019.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('confidence', 1)\n"
     ]
    }
   ],
   "source": [
    "#Resetting dataframe but using different columns now, like negativereason to get the reason\n",
    "data = pd.read_csv('Airline dataset.csv')\n",
    "df = pd.concat([data.tweet_id, data.airline_sentiment,data.airline_sentiment_confidence, data.text, data.negativereason], axis = 1)\n",
    "df.columns = ['id', 'sentiment','confidence', 'text', 'reason']\n",
    "df = df.dropna(axis = 0)\n",
    "# getting rid of every row where reason is not stated\n",
    "df = df[df.reason != \"Can't Tell\"]\n",
    "# resetting the index and removing confidence column\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop('confidence', 1)\n",
    "#Applying the decontracted  function to every row in the text column of the dataframe with a lambda function  \n",
    "df.text = df.text.apply(lambda y: decontracted(y))\n",
    "#Applying the process text function to every row in the text column of the dataframe with a lambda function    \n",
    "df.text = df.text.apply(lambda x: (process_text_MB(x)))\n",
    "#TF-IDF again\n",
    "corpus = df.text\n",
    "bow = vectorizer.fit_transform(corpus)\n",
    "transformer = TfidfTransformer()\n",
    "text_tfidf = transformer.fit_transform(bow)\n",
    "text_tfidf = text_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dacce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6320400500625782\n"
     ]
    }
   ],
   "source": [
    "#Train/Test split\n",
    "Y = df.reason\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     text_tfidf,Y, test_size=0.2, random_state=3)\n",
    "\n",
    "#Building and testing RF classifier to predict reason\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "random_forest_classifier.fit(X_train,y_train)\n",
    "random_forest_classifier_prediction =  random_forest_classifier.predict(X_test)\n",
    "results = pd.DataFrame(data=random_forest_classifier_prediction, columns=[\"prediction\"])\n",
    "print(accuracy_score(random_forest_classifier_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d63f2f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>[baggage, claim, going, newarktiredandwanttogo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Late Flight</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>[descending, farce, flight, get, going, not, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>[cancelled, decided, drive, eventually, flight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Late Flight</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>[houston, not, notconditions, notdestination, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flight Attendant Complaints</td>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>[bag, carry, easily, fit, let, loyal, not, ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>[airline, customer, get, inferior, nation, nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>[answer, cancelled, dm, employee, flighted, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>[account, added, elevate, excited, first, flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>[2, already, another, anything, could, first, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>[12, 2, answer, bna, ca, help, hold, hr, human...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Label              Prediction  \\\n",
       "0                    Lost Luggage            Lost Luggage   \n",
       "1                     Late Flight             Late Flight   \n",
       "2                Cancelled Flight        Cancelled Flight   \n",
       "3                     Late Flight             Late Flight   \n",
       "4     Flight Attendant Complaints            Lost Luggage   \n",
       "...                           ...                     ...   \n",
       "1593       Customer Service Issue  Customer Service Issue   \n",
       "1594       Customer Service Issue        Cancelled Flight   \n",
       "1595      Flight Booking Problems  Customer Service Issue   \n",
       "1596       Customer Service Issue  Customer Service Issue   \n",
       "1597       Customer Service Issue  Customer Service Issue   \n",
       "\n",
       "                                                   text  \n",
       "0     [baggage, claim, going, newarktiredandwanttogo...  \n",
       "1     [descending, farce, flight, get, going, not, n...  \n",
       "2     [cancelled, decided, drive, eventually, flight...  \n",
       "3     [houston, not, notconditions, notdestination, ...  \n",
       "4     [bag, carry, easily, fit, let, loyal, not, ove...  \n",
       "...                                                 ...  \n",
       "1593  [airline, customer, get, inferior, nation, nat...  \n",
       "1594  [answer, cancelled, dm, employee, flighted, ha...  \n",
       "1595  [account, added, elevate, excited, first, flig...  \n",
       "1596  [2, already, another, anything, could, first, ...  \n",
       "1597  [12, 2, answer, bna, ca, help, hold, hr, human...  \n",
       "\n",
       "[1598 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reverting the TF-IDF array into text\n",
    "text = vectorizer.inverse_transform(X_test)\n",
    "#Creating result dataframe to see the actual label, predicted label and text that was given to classifier\n",
    "a = results\n",
    "y_test = y_test.reset_index()\n",
    "y_test['result'] = a\n",
    "y_test.drop(columns=\"index\", inplace=True)\n",
    "y_test.columns  = [\"Label\", \"Prediction\"]\n",
    "results = y_test\n",
    "results['text'] = text\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b553627",
   "metadata": {},
   "source": [
    "# III. Conclusions\n",
    "\n",
    "## 9. Evaluation\n",
    "\n",
    "Because the test and train data is selected randomly at every run of this code, results may vary some percent.\n",
    "\n",
    "The baseline Naive Bayes Classifier achieved a Recall of 0.66 for negative labeled tweets and an accuracy score of 82%. \n",
    "\n",
    "The Random Forest Classifier achieved a Recall of 0.89 for negative labeled tweets and has an accuracy score of 93%. \n",
    "\n",
    "One of the main objectives for this classifier was to have a high recall on negative labeled tweets, so a business can identify all negative tweets and act on the problems/complaints of the costumers. \n",
    "\n",
    "The RF classifier find 90% of all negative labeled tweets which is way higher than the baseline but could still be better. When a user on twitter complains about a product or service and the tweet goes viral, the brand/company will be damaged forever. This damage limitation is crucial that‚Äôs why a high recall is crucial. \n",
    "\n",
    "The Classifier buit to predict the negative reason did not do as well with an accuracy score of 62%. Since any reason for a negative tweet is bad, there is no need to make a distinction between ‚ÄòLost Luggage‚Äô or ‚ÄòCostumer Service‚Äô.\n",
    "\n",
    "In conclusion the results achieved by the random forest classifier are still pretty satisfying, beating the baseline handily, accurately predicting the labels and having a high recall rate on negative labeled tweets.\n",
    "\n",
    "\n",
    "## 10. Evaluation of the project and its results\n",
    "\n",
    "In general, the project was a success. \n",
    "The results clearly show that the optimized pre-processing steps lead to improved results, which was one of the objectives.\n",
    "\n",
    "Furthermore, did the Random Forest classifier perform quite well with roughly 93% accuracy score and 89% recall of negative tweets, which beat the baseline by quite some bit. \n",
    "\n",
    "The classifier or this approach in general could easily work with a bigger dataset, so this approach is scalable. Only runtime could become a problem if the input data becomes too big, as the Random Forest classifier already takes up much memory and runtime.\n",
    "\n",
    "The classifier which should predict the negative reason was not that great with an accuracy score of only about 62%, but it also had a much more complex task then just classifying the sentiment. \n",
    "\n",
    "The general approach of this project can be reproduced and applied to different sentiment classification challenges not just twitter sentiment analysis. \n",
    "\n",
    "As discussed in Lecture 5.201, another approach to sentiment analysis is to use some kind of sentiment lexicon, which would be a manually curated word list. \n",
    "\n",
    "For businesses this approach might make sense if their costumers on twitter use special words or definitions.\n",
    "\n",
    "For future work, it would be interesting to have a dataset where every tweet contains emojis. As mentioned in the objective statement, emojis could contribute to detecting sarcasm or irony and are commonly used among twitter users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ddd9fe",
   "metadata": {},
   "source": [
    "## Publication bibliography\n",
    "\n",
    "Go, Alec; Bhayani, Richa; Huang, Lei (2009): Twitter Sentiment Classification using Distant Supervision. Available online at https://d1wqtxts1xzle7.cloudfront.net/34632156/Twitter_Sentiment_Classification_using_Distant_Supervision-with-cover-page-v2.pdf?Expires=1640780630&Signature=JBWweSyVDV6bthq0makhR62ffzECjxzlFq3reXoAHNlwFMJyh7e~mXnqD8wDsQKu5yPyHtUpziPrkWKPNKMNsx--TK-2~G6~FDpxv8Q0~l~A6FUgIKPtNdi~tkrTazeDQT7Tcdwvp308HxpP70I0ggOH3~YlGecwmiztuYMDA1BbQChI4oRyyfmfOCJtqaOEvFTsFQEJKhXTM3erHRtqxFHGNPtP-r3LIyM4LyCpMZUxuQBgv1v~DdFACAdC0thWsvSlF8lK8rsBdPr8Q4NyxMDR50Dlgebg6KLYAw7sw5bl-h5RBQMbgcgQ0AHGd05IFDrA8vpO2E~8AIT83wpZRg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA, checked on 12/29/2021.\n",
    "Pascual, Federico (2019): Twitter Sentiment Analysis in Real-Time. Available online at https://monkeylearn.com/blog/sentiment-analysis-of-twitter/#:~:text=Twitter%20sentiment%20analysis%20allows%20you,mentions%20before%20they%20they%20escalate., checked on 12/29/2021.\n",
    "You, Tony (2019): Understanding Random Forest. Available online at https://towardsdatascience.com/understanding-random-forest-58381e0602d2#:~:text=The%20Random%20Forest%20Classifier,-Random%20forest%2C%20like&text=In%20data%20science%20speak%2C%20the,between%20models%20is%20the%20key., checked on 12/30/2021.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
